{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb7dda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install rasterio geopandas pandas shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22af8598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we did not need all the region (we need only the country)\n",
    "\n",
    "# #1. Use Rasterio’s Windowed Reading\n",
    "\n",
    "# import rasterio\n",
    "# import pandas as pd\n",
    "# from rasterio.windows import Window\n",
    "# import numpy as np\n",
    "\n",
    "# # Filepath for your large TIFF file\n",
    "# raster_file = r'C:\\Users\\NU\\Downloads\\SVDNB_npp_20230101-20230131_00N060E_vcmcfg_v10_c202302080600\\SVDNB_npp_20230101-20230131_00N060E_vcmcfg_v10_c202302080600.avg_rade9h.tif'\n",
    "# with rasterio.open(raster_file) as src:\n",
    "#     print(src.meta)  # Metadata about the raster file\n",
    "#     print(src.descriptions)  # Description of the raster bands\n",
    "# # Output CSV path\n",
    "# output_csv = r'C:\\Users\\NU\\Downloads\\raster_output.csv'\n",
    "\n",
    "# # Step 1: Open the raster file\n",
    "# with rasterio.open(raster_file) as src:\n",
    "#     # Get raster metadata\n",
    "#     transform = src.transform\n",
    "#     crs = src.crs\n",
    "#     band = src.read(1)  # Read first band metadata only\n",
    "\n",
    "#     # Prepare to store data incrementally\n",
    "#     grid_data = []\n",
    "\n",
    "#     # Step 2: Process the raster in windows (chunks)\n",
    "#     window_size = 512  # Size of each chunk (adjust as needed)\n",
    "#     rows, cols = src.height, src.width\n",
    "\n",
    "#     for row_start in range(0, rows, window_size):\n",
    "#         for col_start in range(0, cols, window_size):\n",
    "#             # Define the window (chunk) to read\n",
    "#             window = Window(col_start, row_start, window_size, window_size)\n",
    "#             data = src.read(1, window=window)  # Read the chunk\n",
    "            \n",
    "#             # Transform window coordinates to actual positions\n",
    "#             for i in range(data.shape[0]):\n",
    "#                 for j in range(data.shape[1]):\n",
    "#                     value = data[i, j]\n",
    "#                     if np.isnan(value):  # Skip nodata values\n",
    "#                         continue\n",
    "#                     # Get global coordinates of the cell\n",
    "#                     row_idx, col_idx = row_start + i, col_start + j\n",
    "#                     left, top = transform * (col_idx, row_idx)\n",
    "#                     right, bottom = transform * (col_idx + 1, row_idx + 1)\n",
    "\n",
    "#                     # Append data\n",
    "#                     grid_data.append({\n",
    "#                         'id': row_idx * cols + col_idx + 1,  # Unique ID\n",
    "#                         'left': left,\n",
    "#                         'top': top,\n",
    "#                         'right': right,\n",
    "#                         'bottom': bottom,\n",
    "#                         'row_index': row_idx,\n",
    "#                         'col_index': col_idx,\n",
    "#                         'raster_value': value\n",
    "#                     })\n",
    "\n",
    "#             # Optional: Save intermediate results if needed to avoid memory issues\n",
    "#             if len(grid_data) >= 100000:\n",
    "#                 temp_df = pd.DataFrame(grid_data)\n",
    "#                 temp_df.to_csv(output_csv, mode='a', index=False, header=not bool(temp_df.empty))\n",
    "#                 grid_data = []  # Clear the grid data to save memory\n",
    "\n",
    "#     # Step 3: Save the remaining data (if any) to CSV\n",
    "#     if grid_data:\n",
    "#         df = pd.DataFrame(grid_data)\n",
    "#         df.to_csv(output_csv, mode='a', index=False, header=not bool(pd.read_csv(output_csv).empty))\n",
    "\n",
    "# print(f\"CSV file saved: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee52822",
   "metadata": {},
   "source": [
    "Metadata: The file name SVDNB_npp_20230101-20230131_00N060E_vcmcfg_v10_c202302080600.avg_rade9h provides important metadata that can help understand the contents of the file. Let's break it down:\n",
    "\n",
    "File Name Breakdown:\n",
    "SVDNB:\n",
    "\n",
    "This likely refers to \"Suomi National Polar-orbiting Partnership (Suomi NPP)\". Suomi NPP is a satellite operated by NASA and NOAA that collects environmental data. Specifically, SVDNB refers to the Day/Night Band (DNB) on the VIIRS sensor onboard the Suomi NPP satellite, which is used to observe nighttime lights.\n",
    "npp:\n",
    "\n",
    "Refers to the Suomi National Polar-orbiting Partnership (NPP) mission, which is a collaboration between NASA, NOAA, and other agencies for environmental monitoring.\n",
    "20230101-20230131:\n",
    "\n",
    "The date range for the data. The data collected here corresponds to the period from January 1, 2023, to January 31, 2023.\n",
    "00N060E:\n",
    "\n",
    "This is likely the location or region of interest. The coordinates 00N060E represent a location at 0° latitude (equator) and 60° longitude (East), somewhere in the Indian Ocean.\n",
    "This information indicates that the data pertains to a specific geographic area or grid covering that region.\n",
    "vcmcfg_v10:\n",
    "\n",
    "VCM Configuration: This likely refers to the VIIRS Cloud Mask (VCM) Configuration version 10, which is used for identifying clouds in satellite imagery.\n",
    "This could be part of the processing steps to exclude cloud-covered areas from the nighttime lights data.\n",
    "c202302080600:\n",
    "\n",
    "This appears to be a timestamp in the format cYYYYMMDDHHMM, where:\n",
    "c is a prefix for the date and time.\n",
    "2023-02-08 06:00 refers to February 8, 2023, at 06:00 UTC. This timestamp likely indicates when the data was processed or when the file was generated.\n",
    "avg_rade9h:\n",
    "\n",
    "This likely indicates the averaged radiance values over a 9-hour period (the rade9h suffix suggests radiance averaged over a 9-hour window).\n",
    "This could represent a temporal aggregation of nighttime light data to smooth out fluctuations in light intensity.\n",
    "Summary of Information Derived from the File Name:\n",
    "The file contains nighttime light data from the Suomi NPP satellite (using the VIIRS sensor), collected between January 1, 2023, and January 31, 2023, for a specific geographic region near the equator (0°N, 60°E). The data is processed with cloud masking (vcmcfg_v10) and represents average radiance values (avg_rade9h) over a 9-hour period. The file was generated on February 8, 2023.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ecc6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import box\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Filepaths\n",
    "raster_file = r\"D:\\NU\\semester_5\\data_analysis\\project\\edited_project\\SVDNB_npp_20200101-20200131_00N060W_vcmcfg_v10_c202002111500\\SVDNB_npp_20200101-20200131_00N060W_vcmcfg_v10_c202002111500.avg_rade9h.tif\"\n",
    "boundary_file = r\"D:\\NU\\semester_5\\data_analysis\\project\\edited_project\\geoBoundaries-BRA-ADM1-all\\geoBoundaries-BRA-ADM1.geojson\"\n",
    "output_csv = r\"D:\\NU\\semester_5\\data_analysis\\project\\edited_project\\viirs_dataset.csv\"\n",
    "\n",
    "# Load brazil's Boundary\n",
    "brazil = gpd.read_file(boundary_file)\n",
    "brazil = brazil.to_crs(epsg=4326)\n",
    "\n",
    "# Open the Raster and Check Overlap\n",
    "with rasterio.open(raster_file) as src:\n",
    "    raster_bounds = box(*src.bounds)\n",
    "    print(\"Raster Bounds:\", src.bounds)\n",
    "    print(\"brazil Bounds:\", brazil.total_bounds)\n",
    "\n",
    "    if not raster_bounds.intersects(brazil.unary_union):\n",
    "        raise ValueError(\"brazil's boundary does not overlap with the raster extent.\")\n",
    "\n",
    "    # Clip the raster\n",
    "    brazil_geom_list = [feature[\"geometry\"] for feature in brazil.__geo_interface__[\"features\"]]\n",
    "    clipped_raster, clipped_transform = mask(src, brazil_geom_list, crop=True)\n",
    "\n",
    "# Extract Raster Values\n",
    "light_intensity = clipped_raster[0]\n",
    "rows, cols = np.where(~np.isnan(light_intensity))\n",
    "values = light_intensity[rows, cols]\n",
    "x_coords, y_coords = rasterio.transform.xy(clipped_transform, rows, cols)\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'longitude': x_coords,\n",
    "    'latitude': y_coords,\n",
    "    'light_intensity': values\n",
    "})\n",
    "data.to_csv(output_csv, index=False)\n",
    "print(f\"Extracted data saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084b1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we did not need that\n",
    "\n",
    "# import rasterio\n",
    "# import pandas as pd\n",
    "# from rasterio.windows import Window\n",
    "# from shapely.geometry import box\n",
    "# import numpy as np\n",
    "\n",
    "# # Filepath for your large TIFF file\n",
    "# raster_file = r'C:\\Users\\NU\\Downloads\\SVDNB_npp_20230101-20230131_00N060E_vcmcfg_v10_c202302080600\\SVDNB_npp_20230101-20230131_00N060E_vcmcfg_v10_c202302080600.avg_rade9h.tif'\n",
    "# output_csv = r'C:\\Users\\NU\\Downloads\\indonesia_light_intensity_detailed.csv'\n",
    "\n",
    "# # Define the geographic bounds of Indonesia\n",
    "# indonesia_bounds = {\n",
    "#     \"left\": 95.0,  # Min longitude\n",
    "#     \"right\": 141.0,  # Max longitude\n",
    "#     \"bottom\": -11.0,  # Min latitude\n",
    "#     \"top\": 6.0  # Max latitude\n",
    "# }\n",
    "\n",
    "# # Open the raster file\n",
    "# with rasterio.open(raster_file) as src:\n",
    "#     print(\"Raster Metadata:\", src.meta)  # Metadata about the raster file\n",
    "#     transform = src.transform\n",
    "#     crs = src.crs\n",
    "\n",
    "#     # Get the raster's bounding box\n",
    "#     raster_bounds = box(*src.bounds)\n",
    "#     print(\"Raster Bounds:\", raster_bounds.bounds)\n",
    "\n",
    "#     # Check if the raster covers Indonesia\n",
    "#     indonesia_box = box(indonesia_bounds[\"left\"], indonesia_bounds[\"bottom\"],\n",
    "#                         indonesia_bounds[\"right\"], indonesia_bounds[\"top\"])\n",
    "#     if not raster_bounds.intersects(indonesia_box):\n",
    "#         raise ValueError(\"The raster does not cover the Indonesia region!\")\n",
    "\n",
    "#     # Get pixel indices for Indonesia's bounds\n",
    "#     row_start, col_start = src.index(indonesia_bounds[\"left\"], indonesia_bounds[\"top\"])\n",
    "#     row_end, col_end = src.index(indonesia_bounds[\"right\"], indonesia_bounds[\"bottom\"])\n",
    "\n",
    "#     # Clip indices to raster dimensions\n",
    "#     row_start, col_start = max(row_start, 0), max(col_start, 0)\n",
    "#     row_end, col_end = min(row_end, src.height), min(col_end, src.width)\n",
    "\n",
    "#     # Prepare to store data incrementally\n",
    "#     grid_data = []\n",
    "\n",
    "#     # Process the raster in windows (chunks) for the Indonesia region\n",
    "#     window_size = 512  # Size of each chunk (adjust as needed)\n",
    "#     for row_window_start in range(row_start, row_end, window_size):\n",
    "#         for col_window_start in range(col_start, col_end, window_size):\n",
    "#             # Define the window (chunk) to read\n",
    "#             row_window_end = min(row_window_start + window_size, row_end)\n",
    "#             col_window_end = min(col_window_start + window_size, col_end)\n",
    "#             window = Window(col_window_start, row_window_start,\n",
    "#                             col_window_end - col_window_start,\n",
    "#                             row_window_end - row_window_start)\n",
    "\n",
    "#             # Read the chunk\n",
    "#             data = src.read(1, window=window)\n",
    "\n",
    "#             # Transform window coordinates to actual positions\n",
    "#             for i in range(data.shape[0]):\n",
    "#                 for j in range(data.shape[1]):\n",
    "#                     value = data[i, j]\n",
    "#                     if np.isnan(value):  # Skip nodata values\n",
    "#                         continue\n",
    "#                     # Get global coordinates of the cell\n",
    "#                     global_row_idx = row_window_start + i\n",
    "#                     global_col_idx = col_window_start + j\n",
    "#                     left, top = transform * (global_col_idx, global_row_idx)\n",
    "#                     right, bottom = transform * (global_col_idx + 1, global_row_idx + 1)\n",
    "\n",
    "#                     # Append data\n",
    "#                     grid_data.append({\n",
    "#                         'id': global_row_idx * src.width + global_col_idx + 1,  # Unique ID\n",
    "#                         'left': left,\n",
    "#                         'top': top,\n",
    "#                         'right': right,\n",
    "#                         'bottom': bottom,\n",
    "#                         'row_index': global_row_idx,\n",
    "#                         'col_index': global_col_idx,\n",
    "#                         'raster_value': value\n",
    "#                     })\n",
    "\n",
    "#             # Optional: Save intermediate results to avoid memory issues\n",
    "#             if len(grid_data) >= 100000:\n",
    "#                 temp_df = pd.DataFrame(grid_data)\n",
    "#                 temp_df.to_csv(output_csv, mode='a', index=False, header=not bool(pd.read_csv(output_csv).empty))\n",
    "#                 grid_data = []  # Clear grid data to save memory\n",
    "\n",
    "#     # Save remaining data (if any)\n",
    "#     if grid_data:\n",
    "#         df = pd.DataFrame(grid_data)\n",
    "#         df.to_csv(output_csv, mode='a', index=False, header=not bool(pd.read_csv(output_csv).empty))\n",
    "\n",
    "# print(f\"CSV file saved: {output_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
